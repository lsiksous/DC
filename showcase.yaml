personal_info:
  name: Laurent SIKSOUS
  title: Expert Plateformes Data & Big Data — Environnements Critiques & Cloud
  email: lsiksous@jems-group.com
  phone: ''
  location: FR
  website: https://www.doyoubuzz.com/laurent-siksous/
  linkedin: ''
  github: ''
summary: Avec **29 années d'expérience**, ce profil combine une expertise unique en **architecture mainframe z/OS** et en **intelligence artificielle**. Spécialisé dans la **transformation digitale** des systèmes legacy pour les grands comptes (banques, assurances), il maîtrise parfaitement les technologies Big Data et Machine Learning. Son expérience de **direction d'entreprise** et de management d'équipes, associée à ses compétences techniques avancées en IA et Cloud, en fait un architecte IT de référence pour les projets de modernisation complexes.
skills:
- category: IA
  items:
  - Sci-Kit (80%)
  - PyTorch (60%)
  - TensorFlow (60%)
  - LangChain (40%)
  - RAG (40%)
  - Systèmes agentiques (30%)
- category: Langages de programmation
  items:
  - Python (80%)
  - Shell (80%)
  - C (60%)
  - Ruby (60%)
  - Javascript (60%)
  - R
- category: Container et gestion de Container
  items:
  - Docker (80%)
  - Terraform (80%)
- category: Système d'exploitation
  items:
  - z/OS (100%)
  - z/VM (100%)
  - z/Linux (100%)
  - Unix/Linux (100%)
  - macOS (90%)
- category: Frameworks
  items:
  - Flask
  - Ruby on Rails
- category: Base de données
  items:
  - DB2
  - MySQL
  - PostgreSQL
- category: Big Data
  items:
  - Cloudera
  - Kafka
- category: Cloud
  items:
  - AWS
  - GoogleCloud
  - Azure
- category: Gestion de Conf
  items:
  - Ansible
- category: Versionning
  items:
  - Git
- category: API
  items:
  - API SOAP
  - API REST
  - Swagger
- category: Intégration continue (CI)
  items:
  - GitLab
  - Jenkins
- category: Tests
  items:
  - Test fonctionnel
  - Test manuel
  - Test unitaire
  - Test automatisé
  - Test de performance
  - Test d'API
  - Test de non regression
- category: Monitoring
  items:
  - Grafana
  - Nagios
  - Dynatrace
  - Prometheus
- category: Outils
  items:
  - Github
  - Jira
  - Trello
- category: Environnement de développement (IDE)
  items:
  - Visual Studio Code
- category: Méthodes
  items:
  - Scrum
  - UML
  - Cycle en V
  - Devops
  - Itérative
  - Cascade
  - Lean
- category: Serveur
  items:
  - Apache
  - Nginx
experience:
- title: Administrateur Hadoop
  company: CAGIP
  location: ''
  start_date: 2024-12
  end_date: 2026-02
  context: Exploitation et fiabilisation de plateformes Big Data critiques en environnement bancaire, avec de fortes contraintes de disponibilité, sécurité et performance.
  missions:
  - Administration et exploitation de clusters Hadoop / Cloudera en production (>100 nœuds)
  - Support expert N3 / N4 sur incidents critiques (HDFS, YARN, Kafka, Spark, OS)
  - Analyse approfondie de logs applicatifs et systèmes (volumétrie élevée)
  - Stabilisation de plateformes soumises à des pics allant jusqu’à 1 000 connexions SSH simultanées
  - "Optimisation mémoire et tuning système, réduction significative des incidents OOM\t•\tAutomatisation des tâches d’exploitation et de diagnostic via Bash et Python"
  - Amélioration du monitoring et de l’observabilité, réduction du bruit d’alertes
  environments:
  - Cloudera
  - Hadoop, HDFS, YARN, Spark, Kafka, Hive, HBase, Cloudera, Linux, Bash, Python, ELK, Prometheus, Grafana
- title: Data Engineer
  company: Jems
  location: ''
  start_date: 2024-06
  end_date: 2024-11
  context: Réalisation d’un MVP de l’outil Platform Builder de JEMS, visant à concevoir une plateforme data cloud industrialisable et multi-cloud, permettant de générer et déployer des pipelines data standardisés sur AWS, Azure et Google Cloud Platform, avec un socle Apache Iceberg pour la gestion des tables analytiques.
  missions:
  - Contribution à la conception et à la livraison du MVP Platform Builder
  - Conception et développement de pipelines data cloud en PySpark
  - Mise en œuvre de tables analytiques Apache Iceberg (évolution de schéma, historisation / time travel)
  - Structuration des chaînes ingestion → transformation
  - Développement de jobs Spark industrialisés (hors notebooks exploratoires)
  - Déploiement et validation des pipelines sur AWS, Azure et GCP
  environments:
  - Platform Builder (JEMS), Apache Iceberg, Python, PySpark, Apache Spark, AWS, Azure, Google Cloud Platform, Data Pipelines, Industrialisation, Git
- title: Développeur IA
  company: IFIP
  location: ''
  start_date: '2021'
  end_date: '2023'
  context: Étude sur la prévision de la production dans le secteur de la viande porcine en France. Les données utilisées proviennent d'un organisme, BDPORC qui est chargé par l'état, pour des raisons de traçabilité de collecter les mouvements d'animaux avec environ 800 000 à 900 000 enregistrements par an.
  missions:
  - '- Développement d''un pipeline de traitement des données, qui comprend la sélection des caractéristiques, la transformation des caractéristiques, et l''entraînement des modèles de prévision

    - Comparaison de la performance de plusieurs modèles de prévision de séries temporelles, tels que DeepAR, Prophet, HRHN, N-BEATS, DSTP-RNN, TFT, N-HITS, Catboost, XGBoost, LightGBM et Croston, en utilisant la métrique MAPE (Mean Absolute Percentage Error)

    - Obtention de la meilleure performance avec Catboost avec une MAPE de 3,45%'
  environments:
  - '- Azure, Pytorch, Tensorflow, Scikit-learn, R Studio

    - Streamlit, docker, kedro, optuna, ray, mlflow, great expectations, wandb'
- title: Data Scientist
  company: Ikkoe
  location: ''
  start_date: '2020'
  end_date: '2021'
  context: L'entreprise Ikkoe est une entreprise B2B se situant dans la personnalisation de produits de luxe. Elle a développé un configurateur qui permet aux consommateurs de ses clients de personnaliser leurs produits avec des messages ou des images (broderie, imprimerie...).
  missions:
  - '- Conception et mise en œuvre d''une API NLP d''aide/inspiration à la rédaction de messages pour la personnalisation de produits

    - Fine tuning de différents modèles sur un corpus de textes suggérant l''aventure, les activités de plein air pour la marque AIGLE

    - R&D génération de formes 3D à partir d''une seule image 2D'
  environments:
  - '- AWS, GPT-2, GPT-3, BERT'
- title: Sales Responsible
  company: Syspertec Group
  location: ''
  start_date: '2014'
  end_date: '2017'
  context: Management de transition dans le cadre du rachat de Blondeau Informatique par le groupe Syspertec (Continuité des contrats et intégration du personnel).
  missions:
  - '- Développement de l''offre z/Heritage ("Rejuvenate the Mainframe") auprès d''une clientèle Grands Comptes (banques, assurances, administration)

    - Collaboration avec des clients de grande envergure pour moderniser et optimiser leurs systèmes mainframe

    - Élaboration de stratégies de transformation digitale adaptées aux besoins spécifiques de chaque client

    - Sur la base d''un constat de raréfaction des compétences, reprise des patrimoines logiciels et recompilation des anciens programmes avec les compilateurs récents'
  environments:
  - '- z/OS, Cobol, Assembleur, Principia

    - Outils maison d''analyse de code'
- title: Directeur du Centre de Service et de Formation
  company: Blondeau Informatique
  location: ''
  start_date: '2009'
  end_date: '2017'
  context: Sur la base d'un constat de raréfaction des compétences de maintien en condition opérationnelle des applications legacy de nos entreprises clientes (volet formation et support technique de l'offre z/Heritage).
  missions:
  - '- Animation du réseau de collaborateurs et de formateurs indépendants

    - Gestion et coordination d''équipes de collaborateurs et de formateurs pour assurer la qualité des services et des formations

    - Mise en place et supervision de programmes de formation adaptés aux besoins des clients

    - Formation des programmeurs sur les langages anciens comme COBOL et Assembleur pour pallier la raréfaction des compétences mainframe

    - En collaboration avec l''Université de Haute Alsace, création d''un diplôme universitaire Développeur Grand Système et d''une licence professionnelle de même intitulé inscrite au RNCP'
  environments:
  - '- z/OS, Assembleur, COBOL'
- title: Directeur Général
  company: Blondeau Informatique
  location: ''
  start_date: '2012'
  end_date: '2014'
  context: Pilotage du rachat de l'entreprise par le groupe Syspertec.
  missions:
  - '- Responsable des négociations et du processus de Due Diligence'
  environments: []
- title: Directeur Général Délégué
  company: Blondeau Informatique
  location: ''
  start_date: '2009'
  end_date: '2012'
  context: Chargé du développement commercial et des ressources humaines dans le cadre des difficultés financières rencontrées par la précédente équipe de direction. Optimisation du P&L, définition d'un axe clair en nous recentrant sur le cœur d'activité qui nous a permis de renouer avec les bénéfices dès la première année.
  missions:
  - '- Création de l''offre z/Heritage ("Rejuvenate the Mainframe")

    - Développement de l''offre z/Heritage ("Rejuvenate the Mainframe") auprès d''une clientèle Grands Comptes (banques, assurances, administration)

    - Collaboration avec des clients de grande envergure pour moderniser et optimiser leurs systèmes mainframe

    - Élaboration de stratégies de transformation digitale adaptées aux besoins spécifiques de chaque client

    - Sur la base d''un constat de raréfaction des compétences, reprise des patrimoines logiciels et recompilation des anciens programmes avec les compilateurs récents'
  environments:
  - '- z/OS, Assembleur, COBOL, Unix System Services'
- title: Chef de Projet
  company: LA POSTE DPI-QST
  location: ''
  start_date: '2005'
  end_date: '2007'
  context: Dans le cadre de l'externalisation de l'hébergement des moyens de production, renumérotation de l'adressage IP d'un millier de serveurs et équipements réseaux.
  missions:
  - '- Définition de la stratégie de migration

    - Étude de l''adhérence des socles et des applications aux adresses IP

    - Mise en œuvre du DNS

    - Intégration des consignes de migration par serveur

    - Mise en œuvre et suivi du planning

    - Pilotage des déploiements

    - Responsable de l''équipe de support niveau 2 lors des relocalisations'
  environments:
  - '- AIX, HP-UX, Solaris, z/OS, Windows Server, Oracle, DB2

    - Progiciels'
- title: Interim Manager
  company: LA POSTE DPI-QST
  location: ''
  start_date: '2004'
  end_date: '2005'
  context: Responsable intérimaire de la division d'intégration "Socles Techniques" (15 personnes).
  missions:
  - '- Mission de qualification et d''intégration des socles de production en informatique centralisée et distribuée'
  environments:
  - '- AIX, HP-UX, Solaris, z/OS, Windows Server, Oracle, DB2

    - Progiciels'
- title: Formateur
  company: IBM Learning Services
  location: ''
  start_date: '1999'
  end_date: '2014'
  context: Dispense de cours inscrits au catalogue de formation des ingénieurs grands systèmes IBM.
  missions:
  - '- z/OS Unix System Services : Concepts et fonctionnalités

    - z/OS Unix System Services : Mise en Œuvre

    - TCP/IP Introduction

    - TCP/IP Architecture

    - OS/390 TCP/IP Mise en Œuvre

    - OS/390 TCP/IP Applications

    - Linux/VM Installation et Administration

    - Linux/VM Mise en Œuvre TCP/IP'
  environments:
  - '- z/OS, Linux, z/VM, TCP/IP'
- title: Architecte Système
  company: DNSCE
  location: ''
  start_date: '2003'
  end_date: '2003'
  context: La Direction Nationale des Statistiques du Commerce Extérieur était à l'origine le centre de traitement des données issues des déclarations douanières utilisées pour produire les indicateurs du commerce extérieur analysés et publiés par l'Insee.
  missions:
  - '- Analyse de dimensionnement d''un système central OS/390 sous VM

    - Étude de migration de la base de données séquentielle propriétaire à cette plateforme vers Oracle'
  environments:
  - '- OS/390, VM, Oracle'
- title: Architecte Système
  company: Blondeau Informatique
  location: ''
  start_date: '2000'
  end_date: '2002'
  context: Suite à la commercialisation de solutions Linux sur Mainframe par IBM, mise à disposition d'une plateforme de tests pour divers clients grands comptes dont France Telecom.
  missions:
  - '- Spécification et mise en œuvre d''une infrastructure d''hébergement de projets de R&D sur la plateforme Linux sous VM

    - Réalisation d''une plateforme de démonstration de Webmail et JEE sous Debian S/390 présentée à Linux Expo Paris (Blondeau Informatique/Alcove)'
  environments:
  - '- OS/390, VM, Oracle'
- title: Chef de Projet/Ingénieur Système
  company: La Banque Postale
  location: ''
  start_date: '2000'
  end_date: '2000'
  context: Création d'un environnement Sysplex de tests et de pré-production au sein d'une équipe de 4 personnes.
  missions:
  - '- Duplication des 4 partitions de la production et mise en place des processus de gestion des sources et de réplication des données de tests'
  environments:
  - '- OS/390, Sysplex, SMP/E, DB2, CICS, RACF, TWS'
- title: Administrateur Système et Réseau
  company: Groupe Yves Rocher
  location: ''
  start_date: '1997'
  end_date: '1999'
  context: Administration du SI central (Fichier clients, gestion des commandes pour ce client leader de la VPC).
  missions:
  - '- Étude de restructuration de la bandothèque

    - Conception et réalisation d''un journal de bord pour le bandothéquaire en C/shell/Motif

    - Étude et mise en œuvre du Disaster Recovery Plan'
  environments:
  - '- OS/390, HP-UX, C, DB2, CICS'
- title: Analyste d'Exploitation
  company: Groupe Yves Rocher
  location: ''
  start_date: '1996'
  end_date: '1997'
  context: ''
  missions:
  - '- Surveillance du plan et gestion des incidents

    - Conception d''un script d''automatisation du suivi et du contrôle de l''exécution des travaux'
  environments:
  - '- OS/390, HP-UX, TWS, HSM, STORAGETEK'
education: []
projects: []
certifications:
- name: Administrateur Hadoop
  issuer: DataScientest
  date: Mai 2024
  credential_url: ''
- name: Big Data Machine Learning with Apache Spark
  issuer: CDOSS
  date: Mars 2024
  credential_url: ''
- name: Hadoop Cluster Installation and Administration
  issuer: CDOSS
  date: Mars 2024
  credential_url: ''
- name: Managing Big Data in Hadoop Cluster
  issuer: CDOSS
  date: Mars 2024
  credential_url: ''
- name: Développeur en Intelligence artificielle
  issuer: Microsoft/Simplon
  date: Mars 2023
  credential_url: ''
- name: 'Microsoft Certified: Azure AI Fundamentals'
  issuer: Microsoft
  date: Mars 2022
  credential_url: ''
- name: 'Microsoft Certified: Azure Fundamentals'
  issuer: Microsoft
  date: Mars 2022
  credential_url: ''
- name: Ingénieur système OS/390
  issuer: IBM Learning Services
  date: '1999'
  credential_url: ''
languages:
- language: EN
  proficiency: Bilingue (95%)
